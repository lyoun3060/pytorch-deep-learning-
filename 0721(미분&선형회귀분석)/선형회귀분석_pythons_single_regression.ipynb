{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]\n",
      " [2]\n",
      " [3]\n",
      " [4]\n",
      " [5]]\n",
      "[[ 3]\n",
      " [ 5]\n",
      " [ 7]\n",
      " [ 9]\n",
      " [11]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# x_data=np.array([1,2,3,4,5]).reshape(5,1)\n",
    "x_data=np.array([[1,1],[2,2],[3,3],[4,4],[5,5]]).reshape(5,2)\n",
    "\n",
    "t_data=np.array([3,5,7,9,11]).reshape(5,1) #->y=2x+1의 식\n",
    "print(x_data)\n",
    "print(t_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.63675368]]), array([0.38810093]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w=np.random.rand(1,1)\n",
    "b=np.random.rand(1)\n",
    "w,b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 비용 함수(Cost function) 또는 손실 함수(Loss function) \\\n",
    "기계 학습에서 모델의 예측값과 실제 관측값(라벨 또는 타겟 값) 사이의 차이를 측정하는 함수\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#손실함수 수식\n",
    "# 평균 제곱 오차(Mean Squared Error, MSE)를 계산 \n",
    "# MSE는 회귀 문제에서 주로 사용되는 손실 함수로, 모델이 예측한 값과 실제 라벨 간의 차이를 측정하는 데 사용\n",
    "\n",
    "def loss_func(x,t):\n",
    "    y=np.dot(x,w)+b\n",
    "    \n",
    "    return (np.sum((t-y)**2))/len(x)\n",
    "\n",
    "#def loss_func(x, t):: 손실 함수 loss_func는 두 개의 인자 x와 t를 받습니다. 여기서 x는 입력 데이터의 배열이고, t는 해당 입력 데이터에 대한 실제 라벨 또는 타겟값의 배열입니다.\n",
    "# y = np.dot(x, w) + b: 주어진 입력 데이터 x와 가중치 w를 내적하고 편향 b를 더하여 예측값 y를 계산합니다. 이 과정은 선형 회귀 모델의 예측을 나타냅니다.\n",
    "# (np.sum((t - y)**2)) / len(x): 예측값 y와 실제 라벨 t 간의 평균 제곱 오차(MSE)를 계산합니다.\n",
    "# 먼저 (t - y)**2를 통해 각 데이터 포인트에서 오차를 제곱합니다. 그런 다음 np.sum을 사용하여 모든 데이터 포인트의 제곱 오차를 더합니다. 최종적으로 len(x)로 나누어 데이터 포인트의 수로 평균을 구합니다.\n",
    "# 최종적으로 계산된 평균 제곱 오차(MSE)를 반환합니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 수치 미분 구현\n",
    "def numerical_derivative(f,x):\n",
    "    delta_x=1e-4\n",
    "    grad=np.zeros_like(x)\n",
    "    \n",
    "    it=np.nditer(x, flags=['multi_index'], op_flags=['readwrite'])\n",
    "    \n",
    "    while not it.finished:\n",
    "        idx=it.multi_index\n",
    "        tmp_val=x[idx]\n",
    "        x[idx]=float(tmp_val)+delta_x\n",
    "        fx1=f(x) # f(x+delta_x)\n",
    "\n",
    "        x[idx]=float(tmp_val)-delta_x\n",
    "        fx2=f(x) # f(x-delta_x)\n",
    "        grad[idx]=(fx1-fx2)/(2*delta_x)\n",
    "\n",
    "        x[idx]=tmp_val\n",
    "        it.iternext()\n",
    "\n",
    "    return grad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x):\n",
    "    y=np.dot(x,w)+b\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial error value= 25.822281341062354 Initial w= [[0.63675368]] b= [0.38810093]\n",
      "step= 0 error value= 15.197224527676587 w= [[0.97338181]] b= [0.461936]\n",
      "step= 400 error value= 0.0010338044811080277 w= [[2.0208793]] b= [0.92463755]\n",
      "step= 800 error value= 6.596283771860724e-05 w= [[2.00527408]] b= [0.98096357]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step= 1200 error value= 4.2088190169459e-06 w= [[2.00133222]] b= [0.99519143]\n",
      "step= 1600 error value= 2.6854753570467605e-07 w= [[2.00033652]] b= [0.99878536]\n",
      "step= 2000 error value= 1.713492042350072e-08 w= [[2.000085]] b= [0.99969318]\n",
      "step= 2400 error value= 1.0933092241924825e-09 w= [[2.00002147]] b= [0.9999225]\n",
      "step= 2800 error value= 6.975959211092618e-11 w= [[2.00000542]] b= [0.99998042]\n",
      "step= 3200 error value= 4.451074391344692e-12 w= [[2.00000137]] b= [0.99999505]\n",
      "step= 3600 error value= 2.8400486043372805e-13 w= [[2.00000035]] b= [0.99999875]\n",
      "step= 4000 error value= 1.8121189021562948e-14 w= [[2.00000009]] b= [0.99999968]\n",
      "step= 4400 error value= 1.156238955977447e-15 w= [[2.00000002]] b= [0.99999992]\n",
      "step= 4800 error value= 7.377487700092139e-17 w= [[2.00000001]] b= [0.99999998]\n",
      "step= 5200 error value= 4.707270288560162e-18 w= [[2.]] b= [0.99999999]\n",
      "step= 5600 error value= 3.0035131641329324e-19 w= [[2.]] b= [1.]\n",
      "step= 6000 error value= 1.9164028826260333e-20 w= [[2.]] b= [1.]\n",
      "step= 6400 error value= 1.2227370865212666e-21 w= [[2.]] b= [1.]\n",
      "step= 6800 error value= 7.801136352729649e-23 w= [[2.]] b= [1.]\n",
      "step= 7200 error value= 4.983088083469303e-24 w= [[2.]] b= [1.]\n",
      "step= 7600 error value= 3.192572148249179e-25 w= [[2.]] b= [1.]\n",
      "step= 8000 error value= 2.0338766845815476e-26 w= [[2.]] b= [1.]\n",
      "step= 8400 error value= 1.351042629326766e-27 w= [[2.]] b= [1.]\n",
      "step= 8800 error value= 1.5761440886315817e-28 w= [[2.]] b= [1.]\n",
      "step= 9200 error value= 1.5761440886315817e-28 w= [[2.]] b= [1.]\n",
      "step= 9600 error value= 1.5761440886315817e-28 w= [[2.]] b= [1.]\n",
      "step= 10000 error value= 1.5761440886315817e-28 w= [[2.]] b= [1.]\n",
      "step= 10400 error value= 1.5761440886315817e-28 w= [[2.]] b= [1.]\n",
      "step= 10800 error value= 1.5761440886315817e-28 w= [[2.]] b= [1.]\n",
      "step= 11200 error value= 1.5761440886315817e-28 w= [[2.]] b= [1.]\n",
      "step= 11600 error value= 1.5761440886315817e-28 w= [[2.]] b= [1.]\n",
      "step= 12000 error value= 1.5761440886315817e-28 w= [[2.]] b= [1.]\n",
      "step= 12400 error value= 1.5761440886315817e-28 w= [[2.]] b= [1.]\n",
      "step= 12800 error value= 1.5761440886315817e-28 w= [[2.]] b= [1.]\n",
      "step= 13200 error value= 1.5761440886315817e-28 w= [[2.]] b= [1.]\n",
      "step= 13600 error value= 1.5761440886315817e-28 w= [[2.]] b= [1.]\n",
      "step= 14000 error value= 1.5761440886315817e-28 w= [[2.]] b= [1.]\n",
      "step= 14400 error value= 1.5761440886315817e-28 w= [[2.]] b= [1.]\n",
      "step= 14800 error value= 1.5761440886315817e-28 w= [[2.]] b= [1.]\n",
      "step= 15200 error value= 1.5761440886315817e-28 w= [[2.]] b= [1.]\n",
      "step= 15600 error value= 1.5761440886315817e-28 w= [[2.]] b= [1.]\n",
      "step= 16000 error value= 1.5761440886315817e-28 w= [[2.]] b= [1.]\n",
      "step= 16400 error value= 1.5761440886315817e-28 w= [[2.]] b= [1.]\n",
      "step= 16800 error value= 1.5761440886315817e-28 w= [[2.]] b= [1.]\n",
      "step= 17200 error value= 1.5761440886315817e-28 w= [[2.]] b= [1.]\n",
      "step= 17600 error value= 1.5761440886315817e-28 w= [[2.]] b= [1.]\n",
      "step= 18000 error value= 1.5761440886315817e-28 w= [[2.]] b= [1.]\n",
      "step= 18400 error value= 1.5761440886315817e-28 w= [[2.]] b= [1.]\n",
      "step= 18800 error value= 1.5761440886315817e-28 w= [[2.]] b= [1.]\n",
      "step= 19200 error value= 1.5761440886315817e-28 w= [[2.]] b= [1.]\n",
      "step= 19600 error value= 1.5761440886315817e-28 w= [[2.]] b= [1.]\n",
      "step= 20000 error value= 1.5761440886315817e-28 w= [[2.]] b= [1.]\n"
     ]
    }
   ],
   "source": [
    "learning_rate=1e-2\n",
    "\n",
    "f=lambda x: loss_func(x_data, t_data)\n",
    "\n",
    "print(\"Initial error value=\", loss_func(x_data, t_data), \"Initial w=\", w, \"b=\",b)\n",
    "\n",
    "for step in range(20001):\n",
    "    w-=learning_rate*numerical_derivative(f, w)\n",
    "    b-=learning_rate*numerical_derivative(f, b)\n",
    "\n",
    "    if step % 400==0:\n",
    "        print(\"step=\", step, \"error value=\", loss_func(x_data, t_data), \"w=\",w, \"b=\",b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (2,) and (1,1) not aligned: 2 (dim 0) != 1 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m predict(np\u001b[39m.\u001b[39;49marray([\u001b[39m10\u001b[39;49m,\u001b[39m20\u001b[39;49m]))\n",
      "Cell \u001b[1;32mIn[23], line 2\u001b[0m, in \u001b[0;36mpredict\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict\u001b[39m(x):\n\u001b[1;32m----> 2\u001b[0m     y\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39;49mdot(x,w)\u001b[39m+\u001b[39mb\n\u001b[0;32m      3\u001b[0m     \u001b[39mreturn\u001b[39;00m y\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mdot\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: shapes (2,) and (1,1) not aligned: 2 (dim 0) != 1 (dim 0)"
     ]
    }
   ],
   "source": [
    "predict(np.array([10,20]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
