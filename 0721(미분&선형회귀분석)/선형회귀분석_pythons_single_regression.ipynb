{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1]\n",
      " [2 2]\n",
      " [3 3]\n",
      " [4 4]\n",
      " [5 5]]\n",
      "[[ 3]\n",
      " [ 5]\n",
      " [ 7]\n",
      " [ 9]\n",
      " [11]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# x_data=np.array([1,2,3,4,5]).reshape(5,1)\n",
    "x_data=np.array([[1,1],[2,2],[3,3],[4,4],[5,5]]).reshape(5,2)\n",
    "t_data=np.array([3,5,7,9,11]).reshape(5,1) #->y=2x+1의 식\n",
    "print(x_data)\n",
    "print(t_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.26640848],\n",
       "        [0.87824552]]),\n",
       " array([0.2903915]))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w=np.random.rand(2,1)\n",
    "b=np.random.rand(1)\n",
    "w,b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 비용 함수(Cost function) 또는 손실 함수(Loss function) \\\n",
    "기계 학습에서 모델의 예측값과 실제 관측값(라벨 또는 타겟 값) 사이의 차이를 측정하는 함수\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#손실함수 수식\n",
    "# 평균 제곱 오차(Mean Squared Error, MSE)를 계산 \n",
    "# MSE는 회귀 문제에서 주로 사용되는 손실 함수로, 모델이 예측한 값과 실제 라벨 간의 차이를 측정하는 데 사용\n",
    "\n",
    "def loss_func(x,t):\n",
    "    y=np.dot(x,w)+b\n",
    "    \n",
    "    return (np.sum((t-y)**2))/len(x)\n",
    "\n",
    "#def loss_func(x, t):: 손실 함수 loss_func는 두 개의 인자 x와 t를 받습니다. 여기서 x는 입력 데이터의 배열이고, t는 해당 입력 데이터에 대한 실제 라벨 또는 타겟값의 배열입니다.\n",
    "# y = np.dot(x, w) + b: 주어진 입력 데이터 x와 가중치 w를 내적하고 편향 b를 더하여 예측값 y를 계산합니다. 이 과정은 선형 회귀 모델의 예측을 나타냅니다.\n",
    "# (np.sum((t - y)**2)) / len(x): 예측값 y와 실제 라벨 t 간의 평균 제곱 오차(MSE)를 계산합니다.\n",
    "# 먼저 (t - y)**2를 통해 각 데이터 포인트에서 오차를 제곱합니다. 그런 다음 np.sum을 사용하여 모든 데이터 포인트의 제곱 오차를 더합니다. 최종적으로 len(x)로 나누어 데이터 포인트의 수로 평균을 구합니다.\n",
    "# 최종적으로 계산된 평균 제곱 오차(MSE)를 반환합니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 수치 미분 구현\n",
    "def numerical_derivative(f,x):\n",
    "    delta_x=1e-4\n",
    "    grad=np.zeros_like(x)\n",
    "    \n",
    "    it=np.nditer(x, flags=['multi_index'], op_flags=['readwrite'])\n",
    "    \n",
    "    while not it.finished:\n",
    "        idx=it.multi_index\n",
    "        tmp_val=x[idx]\n",
    "        x[idx]=float(tmp_val)+delta_x\n",
    "        fx1=f(x) # f(x+delta_x)\n",
    "\n",
    "        x[idx]=float(tmp_val)-delta_x\n",
    "        fx2=f(x) # f(x-delta_x)\n",
    "        grad[idx]=(fx1-fx2)/(2*delta_x)\n",
    "\n",
    "        x[idx]=tmp_val\n",
    "        it.iternext()\n",
    "\n",
    "    return grad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x):\n",
    "    y=np.dot(x,w)+b\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial error value= 1.0270968985977573e-28 \n",
      " Initial w= [[0.69408148]\n",
      " [1.30591852]] \n",
      " b= [1.] \n",
      "\n",
      "step= 0 \n",
      " error value= 1.0270968985977573e-28 \n",
      " w= [[0.69408148]\n",
      " [1.30591852]] \n",
      " b= [1.] \n",
      "\n",
      "step= 400 \n",
      " error value= 1.0270968985977573e-28 \n",
      " w= [[0.69408148]\n",
      " [1.30591852]] \n",
      " b= [1.] \n",
      "\n",
      "step= 800 \n",
      " error value= 1.0270968985977573e-28 \n",
      " w= [[0.69408148]\n",
      " [1.30591852]] \n",
      " b= [1.] \n",
      "\n",
      "step= 1200 \n",
      " error value= 1.0270968985977573e-28 \n",
      " w= [[0.69408148]\n",
      " [1.30591852]] \n",
      " b= [1.] \n",
      "\n",
      "step= 1600 \n",
      " error value= 1.0270968985977573e-28 \n",
      " w= [[0.69408148]\n",
      " [1.30591852]] \n",
      " b= [1.] \n",
      "\n",
      "step= 2000 \n",
      " error value= 1.0270968985977573e-28 \n",
      " w= [[0.69408148]\n",
      " [1.30591852]] \n",
      " b= [1.] \n",
      "\n",
      "step= 2400 \n",
      " error value= 1.0270968985977573e-28 \n",
      " w= [[0.69408148]\n",
      " [1.30591852]] \n",
      " b= [1.] \n",
      "\n",
      "step= 2800 \n",
      " error value= 1.0270968985977573e-28 \n",
      " w= [[0.69408148]\n",
      " [1.30591852]] \n",
      " b= [1.] \n",
      "\n",
      "step= 3200 \n",
      " error value= 1.0270968985977573e-28 \n",
      " w= [[0.69408148]\n",
      " [1.30591852]] \n",
      " b= [1.] \n",
      "\n",
      "step= 3600 \n",
      " error value= 1.0270968985977573e-28 \n",
      " w= [[0.69408148]\n",
      " [1.30591852]] \n",
      " b= [1.] \n",
      "\n",
      "step= 4000 \n",
      " error value= 1.0270968985977573e-28 \n",
      " w= [[0.69408148]\n",
      " [1.30591852]] \n",
      " b= [1.] \n",
      "\n",
      "step= 4400 \n",
      " error value= 1.0270968985977573e-28 \n",
      " w= [[0.69408148]\n",
      " [1.30591852]] \n",
      " b= [1.] \n",
      "\n",
      "step= 4800 \n",
      " error value= 1.0270968985977573e-28 \n",
      " w= [[0.69408148]\n",
      " [1.30591852]] \n",
      " b= [1.] \n",
      "\n",
      "step= 5200 \n",
      " error value= 1.0270968985977573e-28 \n",
      " w= [[0.69408148]\n",
      " [1.30591852]] \n",
      " b= [1.] \n",
      "\n",
      "step= 5600 \n",
      " error value= 1.0270968985977573e-28 \n",
      " w= [[0.69408148]\n",
      " [1.30591852]] \n",
      " b= [1.] \n",
      "\n",
      "step= 6000 \n",
      " error value= 1.0270968985977573e-28 \n",
      " w= [[0.69408148]\n",
      " [1.30591852]] \n",
      " b= [1.] \n",
      "\n",
      "step= 6400 \n",
      " error value= 1.0270968985977573e-28 \n",
      " w= [[0.69408148]\n",
      " [1.30591852]] \n",
      " b= [1.] \n",
      "\n",
      "step= 6800 \n",
      " error value= 1.0270968985977573e-28 \n",
      " w= [[0.69408148]\n",
      " [1.30591852]] \n",
      " b= [1.] \n",
      "\n",
      "step= 7200 \n",
      " error value= 1.0270968985977573e-28 \n",
      " w= [[0.69408148]\n",
      " [1.30591852]] \n",
      " b= [1.] \n",
      "\n",
      "step= 7600 \n",
      " error value= 1.0270968985977573e-28 \n",
      " w= [[0.69408148]\n",
      " [1.30591852]] \n",
      " b= [1.] \n",
      "\n",
      "step= 8000 \n",
      " error value= 1.0270968985977573e-28 \n",
      " w= [[0.69408148]\n",
      " [1.30591852]] \n",
      " b= [1.] \n",
      "\n",
      "step= 8400 \n",
      " error value= 1.0270968985977573e-28 \n",
      " w= [[0.69408148]\n",
      " [1.30591852]] \n",
      " b= [1.] \n",
      "\n",
      "step= 8800 \n",
      " error value= 1.0270968985977573e-28 \n",
      " w= [[0.69408148]\n",
      " [1.30591852]] \n",
      " b= [1.] \n",
      "\n",
      "step= 9200 \n",
      " error value= 1.0270968985977573e-28 \n",
      " w= [[0.69408148]\n",
      " [1.30591852]] \n",
      " b= [1.] \n",
      "\n",
      "step= 9600 \n",
      " error value= 1.0270968985977573e-28 \n",
      " w= [[0.69408148]\n",
      " [1.30591852]] \n",
      " b= [1.] \n",
      "\n",
      "step= 10000 \n",
      " error value= 1.0270968985977573e-28 \n",
      " w= [[0.69408148]\n",
      " [1.30591852]] \n",
      " b= [1.] \n",
      "\n",
      "step= 10400 \n",
      " error value= 1.0270968985977573e-28 \n",
      " w= [[0.69408148]\n",
      " [1.30591852]] \n",
      " b= [1.] \n",
      "\n",
      "step= 10800 \n",
      " error value= 1.0270968985977573e-28 \n",
      " w= [[0.69408148]\n",
      " [1.30591852]] \n",
      " b= [1.] \n",
      "\n",
      "step= 11200 \n",
      " error value= 1.0270968985977573e-28 \n",
      " w= [[0.69408148]\n",
      " [1.30591852]] \n",
      " b= [1.] \n",
      "\n",
      "step= 11600 \n",
      " error value= 1.0270968985977573e-28 \n",
      " w= [[0.69408148]\n",
      " [1.30591852]] \n",
      " b= [1.] \n",
      "\n",
      "step= 12000 \n",
      " error value= 1.0270968985977573e-28 \n",
      " w= [[0.69408148]\n",
      " [1.30591852]] \n",
      " b= [1.] \n",
      "\n",
      "step= 12400 \n",
      " error value= 1.0270968985977573e-28 \n",
      " w= [[0.69408148]\n",
      " [1.30591852]] \n",
      " b= [1.] \n",
      "\n",
      "step= 12800 \n",
      " error value= 1.0270968985977573e-28 \n",
      " w= [[0.69408148]\n",
      " [1.30591852]] \n",
      " b= [1.] \n",
      "\n",
      "step= 13200 \n",
      " error value= 1.0270968985977573e-28 \n",
      " w= [[0.69408148]\n",
      " [1.30591852]] \n",
      " b= [1.] \n",
      "\n",
      "step= 13600 \n",
      " error value= 1.0270968985977573e-28 \n",
      " w= [[0.69408148]\n",
      " [1.30591852]] \n",
      " b= [1.] \n",
      "\n",
      "step= 14000 \n",
      " error value= 1.0270968985977573e-28 \n",
      " w= [[0.69408148]\n",
      " [1.30591852]] \n",
      " b= [1.] \n",
      "\n",
      "step= 14400 \n",
      " error value= 1.0270968985977573e-28 \n",
      " w= [[0.69408148]\n",
      " [1.30591852]] \n",
      " b= [1.] \n",
      "\n",
      "step= 14800 \n",
      " error value= 1.0270968985977573e-28 \n",
      " w= [[0.69408148]\n",
      " [1.30591852]] \n",
      " b= [1.] \n",
      "\n",
      "step= 15200 \n",
      " error value= 1.0270968985977573e-28 \n",
      " w= [[0.69408148]\n",
      " [1.30591852]] \n",
      " b= [1.] \n",
      "\n",
      "step= 15600 \n",
      " error value= 1.0270968985977573e-28 \n",
      " w= [[0.69408148]\n",
      " [1.30591852]] \n",
      " b= [1.] \n",
      "\n",
      "step= 16000 \n",
      " error value= 1.0270968985977573e-28 \n",
      " w= [[0.69408148]\n",
      " [1.30591852]] \n",
      " b= [1.] \n",
      "\n",
      "step= 16400 \n",
      " error value= 1.0270968985977573e-28 \n",
      " w= [[0.69408148]\n",
      " [1.30591852]] \n",
      " b= [1.] \n",
      "\n",
      "step= 16800 \n",
      " error value= 1.0270968985977573e-28 \n",
      " w= [[0.69408148]\n",
      " [1.30591852]] \n",
      " b= [1.] \n",
      "\n",
      "step= 17200 \n",
      " error value= 1.0270968985977573e-28 \n",
      " w= [[0.69408148]\n",
      " [1.30591852]] \n",
      " b= [1.] \n",
      "\n",
      "step= 17600 \n",
      " error value= 1.0270968985977573e-28 \n",
      " w= [[0.69408148]\n",
      " [1.30591852]] \n",
      " b= [1.] \n",
      "\n",
      "step= 18000 \n",
      " error value= 1.0270968985977573e-28 \n",
      " w= [[0.69408148]\n",
      " [1.30591852]] \n",
      " b= [1.] \n",
      "\n",
      "step= 18400 \n",
      " error value= 1.0270968985977573e-28 \n",
      " w= [[0.69408148]\n",
      " [1.30591852]] \n",
      " b= [1.] \n",
      "\n",
      "step= 18800 \n",
      " error value= 1.0270968985977573e-28 \n",
      " w= [[0.69408148]\n",
      " [1.30591852]] \n",
      " b= [1.] \n",
      "\n",
      "step= 19200 \n",
      " error value= 1.0270968985977573e-28 \n",
      " w= [[0.69408148]\n",
      " [1.30591852]] \n",
      " b= [1.] \n",
      "\n",
      "step= 19600 \n",
      " error value= 1.0270968985977573e-28 \n",
      " w= [[0.69408148]\n",
      " [1.30591852]] \n",
      " b= [1.] \n",
      "\n",
      "step= 20000 \n",
      " error value= 1.0270968985977573e-28 \n",
      " w= [[0.69408148]\n",
      " [1.30591852]] \n",
      " b= [1.] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "learning_rate=1e-2\n",
    "\n",
    "f=lambda x: loss_func(x_data, t_data)\n",
    "\n",
    "print(\"Initial error value=\", loss_func(x_data, t_data),\"\\n\", \"Initial w=\", w,\"\\n\", \"b=\",b,\"\\n\")\n",
    "\n",
    "for step in range(20001):\n",
    "    w-=learning_rate*numerical_derivative(f, w)\n",
    "    b-=learning_rate*numerical_derivative(f, b)\n",
    "\n",
    "    if step % 400==0:\n",
    "        print(\"step=\", step, \"\\n\",\"error value=\", loss_func(x_data, t_data),\"\\n\", \"w=\",w, \"\\n\",\"b=\",b,\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
