{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "id": "wk0bAmH6WHwm"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.datasets as dsets\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn.init\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.optim as optim"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device='cuda' if torch.cuda.is_available() else 'cpu'\n",
        "torch.manual_seed(777)\n",
        "if device=='cuda':\n",
        "    torch.cuda.manual_seed_all(777)"
      ],
      "metadata": {
        "id": "c54Sa-JMWZ52"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate=0.001\n",
        "training_epochs=30\n",
        "batch_size=32"
      ],
      "metadata": {
        "id": "InLPeci1Wqq-"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cifar10_train = dsets.CIFAR10(root='data/cifar10_data/',\n",
        "                              train=True,\n",
        "                              transform=transforms.ToTensor(),\n",
        "                              download=True)\n",
        "cifar10_test = dsets.CIFAR10(root='data/cifar10_data/',\n",
        "                              train=False,\n",
        "                              transform=transforms.ToTensor(),\n",
        "                              download=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9JIAwN0CWs4u",
        "outputId": "eb513e53-9d39-4f2d-bd7b-b8d0dbf55834"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_loader = DataLoader(dataset=cifar10_train,\n",
        "                       batch_size=batch_size,\n",
        "                       shuffle=True,\n",
        "                       drop_last=True)"
      ],
      "metadata": {
        "id": "U-nKiThuXY03"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_test = DataLoader(dataset=cifar10_test,\n",
        "                       batch_size=batch_size,\n",
        "                       shuffle=True,\n",
        "                       drop_last=True)"
      ],
      "metadata": {
        "id": "8OK-h6yxiiGo"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN(nn.Module):\n",
        "  def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.keep_prob = 0.5\n",
        "\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(3, 8, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "\n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Conv2d(8, 16, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "        # self.layer3 = nn.Sequential(\n",
        "        #     nn.Conv2d(16, 128, kernel_size=3, stride=1, padding=1),\n",
        "        #     nn.ReLU(),\n",
        "        #     nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "        self.fc1 = nn.Linear(8*8*16, 64, bias=True)\n",
        "        self.fc2 = nn.Linear(64, 32)\n",
        "        self.fc3 = nn.Linear(32, 10)\n",
        "        nn.init.uniform_(self.fc1.weight)\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = self.layer1(x)\n",
        "    out = self.layer2(out)\n",
        "    # out = self.layer3(out)\n",
        "    out = out.view(out.size(0), -1)\n",
        "    out = self.fc1(out)\n",
        "    out = self.fc2(out)\n",
        "    out = self.fc3(out)\n",
        "    return out\n"
      ],
      "metadata": {
        "id": "1CH2uV40Xwa-"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = CNN().to(device)\n",
        "criterion = nn.CrossEntropyLoss().to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "YO-_hFdSdnsY"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_batch = len(data_loader)\n",
        "print(total_batch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6kMoGGZpeFwn",
        "outputId": "79fb8a75-9871-480a-f535-65cdd45d3a85"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1562\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(training_epochs):\n",
        "  avg_cost = 0\n",
        "\n",
        "  for X, Y in data_loader:\n",
        "    X=X.to(device)\n",
        "    Y=Y.to(device)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    y_hat=model(X)\n",
        "    cost=criterion(y_hat, Y)\n",
        "\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "    avg_cost+=cost/total_batch\n",
        "  print(epoch, avg_cost)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BzHg9Pu2ecKP",
        "outputId": "40c2403c-253b-4749-d6bf-f8c894e7aa12"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 tensor(2.0427, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1 tensor(1.6021, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2 tensor(1.4537, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "3 tensor(1.3780, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "4 tensor(1.3243, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "5 tensor(1.2768, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "6 tensor(1.2359, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "7 tensor(1.1992, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "8 tensor(1.1727, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "9 tensor(1.1447, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "10 tensor(1.1276, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "11 tensor(1.1048, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "12 tensor(1.0859, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "13 tensor(1.0720, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "14 tensor(1.0534, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "15 tensor(1.0412, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "16 tensor(1.0278, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "17 tensor(1.0250, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "18 tensor(1.0151, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "19 tensor(1.0064, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "20 tensor(0.9949, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "21 tensor(0.9910, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "22 tensor(0.9856, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "23 tensor(0.9763, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "24 tensor(0.9698, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "25 tensor(0.9632, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "26 tensor(0.9574, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "27 tensor(0.9535, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "28 tensor(0.9479, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "29 tensor(0.9494, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracys = 0\n",
        "with torch.no_grad():\n",
        "  for X, Y in data_test:\n",
        "    X = X.to(device)\n",
        "    Y = Y.to(device)\n",
        "    prediction = model(X)\n",
        "    correct_prediction = torch.argmax(prediction, 1) == Y\n",
        "    accuracy = correct_prediction.float().mean()\n",
        "    print('Accuracy: ', accuracy.item())\n",
        "    accuracys += accuracy\n",
        "\n",
        "  print('Accuracy: %.3f' % ( 100. * accuracys / len(data_test)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7EEDQRXJfRoX",
        "outputId": "59b91285-f8ce-44a1-819e-35d97656dc89"
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.59375\n",
            "Accuracy:  0.6875\n",
            "Accuracy:  0.5\n",
            "Accuracy:  0.6875\n",
            "Accuracy:  0.625\n",
            "Accuracy:  0.46875\n",
            "Accuracy:  0.65625\n",
            "Accuracy:  0.71875\n",
            "Accuracy:  0.71875\n",
            "Accuracy:  0.65625\n",
            "Accuracy:  0.71875\n",
            "Accuracy:  0.71875\n",
            "Accuracy:  0.75\n",
            "Accuracy:  0.65625\n",
            "Accuracy:  0.65625\n",
            "Accuracy:  0.625\n",
            "Accuracy:  0.625\n",
            "Accuracy:  0.5625\n",
            "Accuracy:  0.5625\n",
            "Accuracy:  0.5625\n",
            "Accuracy:  0.71875\n",
            "Accuracy:  0.5\n",
            "Accuracy:  0.6875\n",
            "Accuracy:  0.75\n",
            "Accuracy:  0.65625\n",
            "Accuracy:  0.59375\n",
            "Accuracy:  0.71875\n",
            "Accuracy:  0.59375\n",
            "Accuracy:  0.46875\n",
            "Accuracy:  0.6875\n",
            "Accuracy:  0.53125\n",
            "Accuracy:  0.71875\n",
            "Accuracy:  0.5625\n",
            "Accuracy:  0.46875\n",
            "Accuracy:  0.53125\n",
            "Accuracy:  0.5625\n",
            "Accuracy:  0.53125\n",
            "Accuracy:  0.53125\n",
            "Accuracy:  0.59375\n",
            "Accuracy:  0.625\n",
            "Accuracy:  0.5\n",
            "Accuracy:  0.5625\n",
            "Accuracy:  0.59375\n",
            "Accuracy:  0.65625\n",
            "Accuracy:  0.6875\n",
            "Accuracy:  0.78125\n",
            "Accuracy:  0.59375\n",
            "Accuracy:  0.65625\n",
            "Accuracy:  0.5625\n",
            "Accuracy:  0.5\n",
            "Accuracy:  0.625\n",
            "Accuracy:  0.625\n",
            "Accuracy:  0.5\n",
            "Accuracy:  0.53125\n",
            "Accuracy:  0.65625\n",
            "Accuracy:  0.5625\n",
            "Accuracy:  0.625\n",
            "Accuracy:  0.65625\n",
            "Accuracy:  0.71875\n",
            "Accuracy:  0.59375\n",
            "Accuracy:  0.75\n",
            "Accuracy:  0.59375\n",
            "Accuracy:  0.625\n",
            "Accuracy:  0.6875\n",
            "Accuracy:  0.625\n",
            "Accuracy:  0.65625\n",
            "Accuracy:  0.75\n",
            "Accuracy:  0.40625\n",
            "Accuracy:  0.8125\n",
            "Accuracy:  0.625\n",
            "Accuracy:  0.59375\n",
            "Accuracy:  0.71875\n",
            "Accuracy:  0.6875\n",
            "Accuracy:  0.6875\n",
            "Accuracy:  0.71875\n",
            "Accuracy:  0.5625\n",
            "Accuracy:  0.5625\n",
            "Accuracy:  0.6875\n",
            "Accuracy:  0.625\n",
            "Accuracy:  0.71875\n",
            "Accuracy:  0.53125\n",
            "Accuracy:  0.75\n",
            "Accuracy:  0.5625\n",
            "Accuracy:  0.6875\n",
            "Accuracy:  0.65625\n",
            "Accuracy:  0.65625\n",
            "Accuracy:  0.5625\n",
            "Accuracy:  0.78125\n",
            "Accuracy:  0.71875\n",
            "Accuracy:  0.75\n",
            "Accuracy:  0.59375\n",
            "Accuracy:  0.625\n",
            "Accuracy:  0.59375\n",
            "Accuracy:  0.6875\n",
            "Accuracy:  0.46875\n",
            "Accuracy:  0.625\n",
            "Accuracy:  0.46875\n",
            "Accuracy:  0.71875\n",
            "Accuracy:  0.5625\n",
            "Accuracy:  0.6875\n",
            "Accuracy:  0.6875\n",
            "Accuracy:  0.5625\n",
            "Accuracy:  0.6875\n",
            "Accuracy:  0.65625\n",
            "Accuracy:  0.59375\n",
            "Accuracy:  0.59375\n",
            "Accuracy:  0.65625\n",
            "Accuracy:  0.6875\n",
            "Accuracy:  0.65625\n",
            "Accuracy:  0.71875\n",
            "Accuracy:  0.34375\n",
            "Accuracy:  0.78125\n",
            "Accuracy:  0.53125\n",
            "Accuracy:  0.71875\n",
            "Accuracy:  0.71875\n",
            "Accuracy:  0.6875\n",
            "Accuracy:  0.625\n",
            "Accuracy:  0.71875\n",
            "Accuracy:  0.53125\n",
            "Accuracy:  0.5625\n",
            "Accuracy:  0.6875\n",
            "Accuracy:  0.71875\n",
            "Accuracy:  0.59375\n",
            "Accuracy:  0.5625\n",
            "Accuracy:  0.5625\n",
            "Accuracy:  0.59375\n",
            "Accuracy:  0.5625\n",
            "Accuracy:  0.78125\n",
            "Accuracy:  0.6875\n",
            "Accuracy:  0.65625\n",
            "Accuracy:  0.5\n",
            "Accuracy:  0.71875\n",
            "Accuracy:  0.5\n",
            "Accuracy:  0.75\n",
            "Accuracy:  0.5625\n",
            "Accuracy:  0.6875\n",
            "Accuracy:  0.625\n",
            "Accuracy:  0.46875\n",
            "Accuracy:  0.65625\n",
            "Accuracy:  0.625\n",
            "Accuracy:  0.625\n",
            "Accuracy:  0.46875\n",
            "Accuracy:  0.625\n",
            "Accuracy:  0.65625\n",
            "Accuracy:  0.625\n",
            "Accuracy:  0.6875\n",
            "Accuracy:  0.625\n",
            "Accuracy:  0.59375\n",
            "Accuracy:  0.71875\n",
            "Accuracy:  0.65625\n",
            "Accuracy:  0.71875\n",
            "Accuracy:  0.625\n",
            "Accuracy:  0.59375\n",
            "Accuracy:  0.53125\n",
            "Accuracy:  0.625\n",
            "Accuracy:  0.46875\n",
            "Accuracy:  0.8125\n",
            "Accuracy:  0.625\n",
            "Accuracy:  0.625\n",
            "Accuracy:  0.59375\n",
            "Accuracy:  0.625\n",
            "Accuracy:  0.53125\n",
            "Accuracy:  0.65625\n",
            "Accuracy:  0.65625\n",
            "Accuracy:  0.5\n",
            "Accuracy:  0.71875\n",
            "Accuracy:  0.71875\n",
            "Accuracy:  0.53125\n",
            "Accuracy:  0.65625\n",
            "Accuracy:  0.625\n",
            "Accuracy:  0.6875\n",
            "Accuracy:  0.5625\n",
            "Accuracy:  0.59375\n",
            "Accuracy:  0.5\n",
            "Accuracy:  0.4375\n",
            "Accuracy:  0.71875\n",
            "Accuracy:  0.71875\n",
            "Accuracy:  0.59375\n",
            "Accuracy:  0.65625\n",
            "Accuracy:  0.65625\n",
            "Accuracy:  0.5625\n",
            "Accuracy:  0.59375\n",
            "Accuracy:  0.71875\n",
            "Accuracy:  0.625\n",
            "Accuracy:  0.65625\n",
            "Accuracy:  0.65625\n",
            "Accuracy:  0.6875\n",
            "Accuracy:  0.65625\n",
            "Accuracy:  0.59375\n",
            "Accuracy:  0.625\n",
            "Accuracy:  0.53125\n",
            "Accuracy:  0.5625\n",
            "Accuracy:  0.5\n",
            "Accuracy:  0.59375\n",
            "Accuracy:  0.71875\n",
            "Accuracy:  0.75\n",
            "Accuracy:  0.71875\n",
            "Accuracy:  0.59375\n",
            "Accuracy:  0.65625\n",
            "Accuracy:  0.71875\n",
            "Accuracy:  0.375\n",
            "Accuracy:  0.625\n",
            "Accuracy:  0.65625\n",
            "Accuracy:  0.65625\n",
            "Accuracy:  0.6875\n",
            "Accuracy:  0.65625\n",
            "Accuracy:  0.65625\n",
            "Accuracy:  0.5\n",
            "Accuracy:  0.5625\n",
            "Accuracy:  0.5625\n",
            "Accuracy:  0.71875\n",
            "Accuracy:  0.65625\n",
            "Accuracy:  0.59375\n",
            "Accuracy:  0.65625\n",
            "Accuracy:  0.6875\n",
            "Accuracy:  0.6875\n",
            "Accuracy:  0.5625\n",
            "Accuracy:  0.5625\n",
            "Accuracy:  0.46875\n",
            "Accuracy:  0.625\n",
            "Accuracy:  0.5625\n",
            "Accuracy:  0.6875\n",
            "Accuracy:  0.5625\n",
            "Accuracy:  0.46875\n",
            "Accuracy:  0.53125\n",
            "Accuracy:  0.65625\n",
            "Accuracy:  0.625\n",
            "Accuracy:  0.75\n",
            "Accuracy:  0.59375\n",
            "Accuracy:  0.65625\n",
            "Accuracy:  0.65625\n",
            "Accuracy:  0.75\n",
            "Accuracy:  0.65625\n",
            "Accuracy:  0.40625\n",
            "Accuracy:  0.65625\n",
            "Accuracy:  0.59375\n",
            "Accuracy:  0.75\n",
            "Accuracy:  0.59375\n",
            "Accuracy:  0.625\n",
            "Accuracy:  0.625\n",
            "Accuracy:  0.4375\n",
            "Accuracy:  0.78125\n",
            "Accuracy:  0.78125\n",
            "Accuracy:  0.65625\n",
            "Accuracy:  0.6875\n",
            "Accuracy:  0.5625\n",
            "Accuracy:  0.625\n",
            "Accuracy:  0.53125\n",
            "Accuracy:  0.6875\n",
            "Accuracy:  0.5\n",
            "Accuracy:  0.59375\n",
            "Accuracy:  0.5\n",
            "Accuracy:  0.59375\n",
            "Accuracy:  0.625\n",
            "Accuracy:  0.65625\n",
            "Accuracy:  0.65625\n",
            "Accuracy:  0.5625\n",
            "Accuracy:  0.53125\n",
            "Accuracy:  0.59375\n",
            "Accuracy:  0.71875\n",
            "Accuracy:  0.6875\n",
            "Accuracy:  0.5\n",
            "Accuracy:  0.53125\n",
            "Accuracy:  0.5625\n",
            "Accuracy:  0.65625\n",
            "Accuracy:  0.65625\n",
            "Accuracy:  0.5\n",
            "Accuracy:  0.6875\n",
            "Accuracy:  0.59375\n",
            "Accuracy:  0.5\n",
            "Accuracy:  0.6875\n",
            "Accuracy:  0.65625\n",
            "Accuracy:  0.59375\n",
            "Accuracy:  0.65625\n",
            "Accuracy:  0.53125\n",
            "Accuracy:  0.625\n",
            "Accuracy:  0.65625\n",
            "Accuracy:  0.53125\n",
            "Accuracy:  0.5\n",
            "Accuracy:  0.65625\n",
            "Accuracy:  0.625\n",
            "Accuracy:  0.71875\n",
            "Accuracy:  0.5625\n",
            "Accuracy:  0.65625\n",
            "Accuracy:  0.65625\n",
            "Accuracy:  0.75\n",
            "Accuracy:  0.625\n",
            "Accuracy:  0.625\n",
            "Accuracy:  0.59375\n",
            "Accuracy:  0.625\n",
            "Accuracy:  0.65625\n",
            "Accuracy:  0.53125\n",
            "Accuracy:  0.65625\n",
            "Accuracy:  0.6875\n",
            "Accuracy:  0.75\n",
            "Accuracy:  0.53125\n",
            "Accuracy:  0.75\n",
            "Accuracy:  0.625\n",
            "Accuracy:  0.625\n",
            "Accuracy:  0.6875\n",
            "Accuracy:  0.65625\n",
            "Accuracy:  0.59375\n",
            "Accuracy:  0.65625\n",
            "Accuracy:  0.625\n",
            "Accuracy:  0.71875\n",
            "Accuracy:  0.375\n",
            "Accuracy:  0.625\n",
            "Accuracy:  0.625\n",
            "Accuracy:  0.65625\n",
            "Accuracy:  0.5625\n",
            "Accuracy:  0.65625\n",
            "Accuracy:  0.46875\n",
            "Accuracy: 62.340\n"
          ]
        }
      ]
    }
  ]
}